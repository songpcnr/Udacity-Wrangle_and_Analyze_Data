{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first thing that I did is to follow through the main 3 steps of data wrangling which are: gather, access and clean.\n",
    "\n",
    "#### First step: I gathered 3 data from 3 different file formats: .csv file, .tsv file from given url and reading tweets-json into pandas dataframe format. Since I have not received Twitter developer token for more than a week from my request, I therefore have to move on with my project read the data from Udacityâ€™s given file instead.\n",
    "\n",
    "#### Second, I begin assess all 3 dataframes at a time. I used .info(), .value_counts() methods and logical subsetting to select part of dataframes that contain pieces of data that I want. In this part I also list all dirty or messy data issues at the end of the section as well. I separate the issues into 2 main parts: \n",
    "\n",
    "##### 1. Data quality issues:\n",
    "\n",
    "Below are <b>most</b> data quality issues that I have encountered for each table:\n",
    "\n",
    "<b>tw_archive table:</b>\n",
    "\n",
    "- Partial missing values (NaN) in the 6 columns, which can't be cleaned or imputed:\n",
    "- Errorneous data types in some columns:\n",
    "- Data contains duplicates in the form of Retweets:\n",
    "    - For Retweet texts: retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp columns will not be empty.\n",
    "- Problem in text column:\n",
    "    - URL attached at the end of text\n",
    "- Problems in name column:\n",
    "    - Missing dog names are recorded as None: can be cleaned in some records\n",
    "    - Invalid dog names: some are recorded as an article (a, an, the) and 'not'\n",
    "    - Inaccurate dog names: some names are misspelled\n",
    "    - Dog names that begin with lowercase letters are incorrect, most do not have name\n",
    "    \n",
    "<b>image_prediction table:</b>\n",
    "- Invalid algorithm's prediction for all 3 predictions (p1, p2 and p3): can't be cleaned\n",
    "    - Some does not contain actual dog's breed names (ex. paper_towl, orange, Appenzeller, tiger_shark, etc.)\n",
    "- Inconsistent letter case in p1, p2 and p3:\n",
    "    - Some names are capitalized while some are not\n",
    "- Underscore ('_') are used instaed of space (' ') between words in column p1, p2 and p3\n",
    "\n",
    "<b>tw_count table:</b>\n",
    "- Errorneous data type in retweets_count and favorites_count columns:\n",
    "\n",
    "##### 2. Tidiness issues\n",
    "\n",
    "<b>tw_archive table:</b>\n",
    "- The last 4 columns (i.e. doggo, floofer, pupper and puppo) can be combined to only 1 column name dog_stage which contains the current stage of each dog.\n",
    "\n",
    "<b>All tables:</b>\n",
    "- All 3 dataframes can be joined together as only 1 table named 'master_clean'.\n",
    "\n",
    "#### Lastly after the assessing stage, I started cleaning each issues one at a time. After I am done, I stored the clean DataFrame in a CSV file called 'twitter_archive_master.csv'. I also iterated a few times once I found that there are additional pieces of data that needs to be cleaned before I can do the analysis and extract insights.\n",
    "\n",
    "After I am done with my findings and insights, I wrote a report about the insights that I have found and this wrangle report to explain how I cleaned the data. I now truly belief that data wrangling is the most arduous task in data analysis process.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
